# ğŸšš "OptimizaciÃ³n del Problema del Agente Viajero (TSP) mediante una MetaheurÃ­stica HÃ­brida ACO-SA con CalibraciÃ³n de ParÃ¡metros por EvoluciÃ³n Diferencial"

Este proyecto implementa una soluciÃ³n hÃ­brida para el Problema del Agente Viajero (TSP), utilizando el algoritmo Ant Colony Optimization (ACO) para generar rutas iniciales, el Recocido Simulado (SA) para refinarlas, y todo el proceso optimizado automÃ¡ticamente mediante el Algoritmo Evolutivo Diferencial (DE).

## ğŸ§© Â¿QuÃ© es el TSP?

El Problema del Agente Viajero (TSP, por sus siglas en inglÃ©s "Traveling Salesman Problem") es uno de los problemas clÃ¡sicos mÃ¡s conocidos en optimizaciÃ³n combinatoria.

Consiste en encontrar la ruta mÃ¡s corta posible que permita a un viajero visitar una serie de ciudades o clientes **exactamente una vez** y regresar al punto de partida.

## ğŸœ Â¿QuÃ© es ACO (Ant Colony Optimization)?

ACO (Ant Colony Optimization) es una metaheurÃ­stica inspirada en el comportamiento colectivo de las colonias de hormigas.

En la naturaleza, las hormigas encuentran caminos cortos entre su nido y las fuentes de comida dejando feromonas. Cuanto mejor sea el camino (mÃ¡s corto), mÃ¡s feromonas se acumulan, y mÃ¡s probable es que otras hormigas lo sigan, reforzando asÃ­ la soluciÃ³n.

En el TSP, simulamos este comportamiento:

- Cada "hormiga" construye una soluciÃ³n recorriendo ciudades o clientes.
- Las decisiones se toman con base en:
  - **Cantidad de feromona** (lo aprendido)
  - **Visibilidad** (inverso de la distancia)
- DespuÃ©s de cada iteraciÃ³n, se actualizan las feromonas, favoreciendo los caminos mÃ¡s cortos.

## ğŸ”¥ Â¿QuÃ© es el Recocido Simulado (SA)?

El Recocido Simulado (Simulated Annealing, SA) es una metaheurÃ­stica inspirada en el proceso metalÃºrgico de recocido, donde un metal se calienta y luego se enfrÃ­a controladamente para modificar sus propiedades fÃ­sicas.
En optimizaciÃ³n:

- Inicialmente acepta soluciones peores con alta probabilidad (temperatura alta)
- Gradualmente se vuelve mÃ¡s selectivo (enfriamiento)

Este enfoque permite escapar de Ã³ptimos locales y explorar mÃ¡s ampliamente el espacio de soluciones.

En nuestro sistema, SA toma las rutas generadas por ACO y las refina mediante pequeÃ±as modificaciones, aceptando algunas soluciones subÃ³ptimas temporalmente para potencialmente encontrar mejores soluciones globales.

## ğŸ”„ Movimientos de Vecindad del Recocido Simulado (SA)

Durante la optimizaciÃ³n local con SA, se generan **soluciones vecinas** a partir de la soluciÃ³n actual mediante uno de los siguientes tres movimientos aleatorios:

1. **InversiÃ³n de un segmento de ruta:**  
   Se selecciona una ruta y se invierte el orden de visita de un segmento entre dos clientes. Este cambio puede reducir la distancia total si existen trayectos cruzados o ineficientes.

2. **Intercambio de dos clientes:**  
   Se eligen dos clientes (dentro de una misma ruta o entre rutas diferentes) y se intercambian sus posiciones. Esto puede modificar significativamente la estructura del recorrido.

3. **ReubicaciÃ³n de un cliente dentro de una ruta:**  
   Se toma un cliente y se lo mueve a otra posiciÃ³n dentro de la misma ruta. Es Ãºtil para ajustes finos sin alterar mucho la composiciÃ³n de la ruta.

La elecciÃ³n del movimiento se realiza aleatoriamente con igual probabilidad, usando el siguiente criterio:

```bash
if (prob < factor / 3.0)
    aceptado = invertirSegmentoRuta(...);
else if (prob < 2.0 * factor / 3.0)
    aceptado = intercambiarClienteRuta(...);
else
    aceptado = moverClienteDentroDeRuta(...);
```

Donde prob es un nÃºmero aleatorio entre 0 y 1, y factor es calibrado por DE.

Este conjunto de movimientos permite que SA explore diversas configuraciones vecinas, ayudando a escapar de Ã³ptimos locales y mejorando la calidad de las rutas generadas por ACO.

## ğŸ§¬ Â¿QuÃ© es el Algoritmo Evolutivo Diferencial (DE)?

DE es una tÃ©cnica de optimizaciÃ³n basada en poblaciones. Ideal para problemas continuos y para ajustar parÃ¡metros automÃ¡ticamente.

ğŸ“Œ Se basa en tres operadores:

MutaciÃ³n â€“ CombinaciÃ³n de soluciones existentes.

Cruzamiento (recombinaciÃ³n) â€“ Mezcla de individuo mutado y original.

SelecciÃ³n â€“ Se elige el mÃ¡s apto entre ambos.

## ğŸ§  Â¿CÃ³mo se resolviÃ³ el TSP?

El enfoque fue **hÃ­brido** con tres algortimos:

- **ACO** resuelve el TSP directamente.
- **SA** refina las rutas generadas por ACO.
- **DE** encuentra los mejores parÃ¡metros para ambos algoritmos.

## âš™ï¸ Rango de ParÃ¡metros Adaptativos segÃºn el TamaÃ±o del Problema

Para lograr una **mejor calibraciÃ³n** de los algoritmos ACO (Ant Colony Optimization) y SA (Simulated Annealing), se definieron **rangos de parÃ¡metros adaptativos** en funciÃ³n del nÃºmero de clientes en la instancia del TSP.

Esto permite que los algoritmos se ajusten de forma dinÃ¡mica, dependiendo de la complejidad del problema (tamaÃ±o de la instancia).

---

### ğŸ”¢ TamaÃ±os de instancia considerados

| TamaÃ±o del problema | NÃºmero de clientes (`tsp->num_clientes`) |
| ------------------- | ---------------------------------------- |
| **PequeÃ±a**         | `25`                                     |
| **Mediana**         | `50`                                     |
| **Grande**          | `100`                                    |

---

### ğŸ“ Rangos de ParÃ¡metros por TamaÃ±o

#### ğŸ”¸ Instancia PequeÃ±a (`25 clientes`)

| ParÃ¡metro                | MÃ­nimo | MÃ¡ximo |
| ------------------------ | ------ | ------ |
| `alpha`                  | 1.0    | 3.0    |
| `beta`                   | 1.0    | 3.0    |
| `rho`                    | 0.5    | 0.7    |
| `nÃºmero de hormigas`     | 10     | 25     |
| `iteraciones ACO`        | 50     | 100    |
| `temperatura inicial`    | 1000.0 | 2000.0 |
| `temperatura final`      | 0.1    | 0.5    |
| `factor de enfriamiento` | 0.99   | 0.999  |
| `factor de control`      | 0.7    | 0.5    |
| `iteraciones SA`         | 100    | 150    |

---

#### ğŸ”¸ Instancia Mediana (`50 clientes`)

| ParÃ¡metro                | MÃ­nimo | MÃ¡ximo |
| ------------------------ | ------ | ------ |
| `alpha`                  | 2.0    | 4.0    |
| `beta`                   | 2.0    | 4.0    |
| `rho`                    | 0.4    | 0.6    |
| `nÃºmero de hormigas`     | 25     | 40     |
| `iteraciones ACO`        | 100    | 150    |
| `temperatura inicial`    | 1500.0 | 2500.0 |
| `temperatura final`      | 0.1    | 0.3    |
| `factor de control`      | 0.6    | 0.8    |
| `factor de enfriamiento` | 0.95   | 0.999  |
| `iteraciones SA`         | 150    | 200    |

---

#### ğŸ”¸ Instancia Grande (`100 clientes`)

| ParÃ¡metro                | MÃ­nimo | MÃ¡ximo |
| ------------------------ | ------ | ------ |
| `alpha`                  | 3.0    | 5.0    |
| `beta`                   | 3.0    | 5.0    |
| `rho`                    | 0.3    | 0.5    |
| `nÃºmero de hormigas`     | 40     | 50     |
| `iteraciones ACO`        | 150    | 200    |
| `temperatura inicial`    | 2000.0 | 3000.0 |
| `temperatura final`      | 0.1    | 0.2    |
| `factor de enfriamiento` | 0.95   | 0.999  |
| `factor de control`      | 0.6    | 0.9    |
| `iteraciones SA`         | 200    | 300    |

---

### ğŸ§  Â¿Por quÃ© definir rangos diferentes?

Esto permite que el algoritmo DE explore soluciones **mÃ¡s ajustadas al tamaÃ±o del problema**, evitando usar configuraciones demasiado pequeÃ±as para instancias grandes, o demasiado costosas para instancias pequeÃ±as. De esta manera se logra un **balance entre calidad de la soluciÃ³n y tiempo de cÃ³mputo.**

---

## ğŸ” Proceso de OptimizaciÃ³n HÃ­brida (DE + ACO + SA) para TSP

1. **InicializaciÃ³n con DE**:  
   Se genera aleatoriamente una poblaciÃ³n inicial de posibles soluciones, donde cada individuo representa un conjunto de parÃ¡metros para el algoritmo **ACO** y **SA**.

2. **EvaluaciÃ³n de Individuos**:  
   Cada conjunto de parÃ¡metros se evalÃºa ejecutando el algoritmo **ACO** y **SA** con dichos valores.

3. **OptimizaciÃ³n Local**:  
   DespuÃ©s de que **ACO** genera una soluciÃ³n (ruta), se aplica **Recocido Simulado (SA)** como optimizador local. Este paso consiste en realizar pequeÃ±os ajustes en la ruta generada por **ACO** para mejorar su calidad. **SA** se encarga de explorar soluciones vecinas a la actual (cercanas en el espacio de soluciones) para encontrar una mejor soluciÃ³n local. Durante este proceso, **SA** acepta temporalmente soluciones peores con una probabilidad que disminuye gradualmente a medida que "enfrÃ­a" su temperatura, permitiendo escapar de Ã³ptimos locales.

4. **CÃ¡lculo del Fitness**:  
   Se obtiene la **distancia total de la mejor ruta** generada por **ACO** y refinada con **SA**. Esta distancia se utiliza como el valor de fitness del individuo.

5. **EvoluciÃ³n con DE**:  
   El algoritmo **DE** utiliza los valores de fitness para evolucionar la poblaciÃ³n, generando nuevos conjuntos de parÃ¡metros con el objetivo de **minimizar la distancia total**.

6. **Criterio de Paro**:  
   El proceso se repite durante un nÃºmero mÃ¡ximo de generaciones.

---

Este proceso permite **optimizar automÃ¡ticamente** el rendimiento del algoritmo **ACO** y **SA**, **evitando el ajuste manual** de parÃ¡metros y encontrando de manera mÃ¡s eficiente soluciones de alta calidad para el **Problema del Agente Viajero (TSP)**.

## ğŸ¯ Resultados Esperados

El objetivo principal de este proyecto es encontrar la mejor ruta para el **Problema del Agente Viajero(TSP)** mediante el uso combinado del algoritmo **ACO** y el algoritmo **DE**, el cual optimiza automÃ¡ticamente los parÃ¡metros del **ACO** y del **SA**.

---

### ğŸ” Â¿QuÃ© se espera como salida?

1. **La mejor ruta encontrada**  
   La ruta Ã³ptima, que minimiza la distancia total recorrida.

2. **Tiempo de ejecuciÃ³n total**  
   El tiempo total que tomÃ³ ejecutar el proceso de optimizaciÃ³n y encontrar la mejor ruta.

---

### ğŸ“¦ Resultados Generados

3. **Archivo JSON**

   - Se genera un archivo `.json` que contiene todos los **parÃ¡metros optimizados automÃ¡ticamente** durante la ejecuciÃ³n, tales como:
     - Nombre del archivo de entrada
     - Tiempo de ejecuciÃ³n en minutos
     - PoblaciÃ³n y generaciones del DE
     - ParÃ¡metros de ACO (`Î±`, `Î²`, `Ï`, nÃºmero de hormigas, iteraciones ACO)
     - ParÃ¡metros de SA (temperatura inicial, final, factor de enfriamiento, iteraciones SA)
     - Valor de fitness de la soluciÃ³n
     - Ruta generada (lista de ciudades o clientes visitados)

4. **Imagen simulada**

   - Se genera una imagen estÃ¡tica (`.png`) que representa visualmente la **ruta generada** por el algoritmo ACO.

   Ejemplo de visualizaciÃ³n:
   ![Imagen Ruta](Recursos_Readme/Ejemplo_png.png)

5. **GIF simulado**

   - Se crea un **GIF animado** que simula el proceso de construcciÃ³n de la ruta, mostrando cÃ³mo la mejor hormiga recorre las ciudades o clientes a lo largo del tiempo.

   Ejemplo de animaciÃ³n:
   ![Simulador Ruta](Recursos_Readme/Ejemplo_gif.gif)

---

### ğŸ’¾ Ejemplo de archivo JSON

El archivo `JSON` generado tendrÃ¡ una estructura como la siguiente:

```json
{
  "Archivo": "C101",
  "Tiempo Ejecucion en Minutos": 2,
  "Poblacion": 10,
  "Generaciones": 10,
  "Alpha": 2.3476589154906842,
  "Beta": 2.3577138539323181,
  "Rho": 0.2498495201812356,
  "Numero Hormigas": 35,
  "Numero Iteraciones ACO": 100,
  "Temperatura Inicial": 748.30022249291665,
  "Temperatura Final": 0.1,
  "Factor de Enfriamiento": 0.99,
  "Numero Iteraciones SA": 99,
  "Fitness Global": 132.12162500340892,
  "Ruta Clientes": [
    0, 20, 21, 22, 24, 25, 23, 13, 17, 18, 19, 15, 16, 14, 12, 11, 10, 8, 9, 6,
    4, 2, 1, 3, 5, 7, 0
  ]
}
```

## Requisitos

Para ejecutar este proyecto, asegÃºrate de tener lo siguiente:

### ğŸ§‘â€ğŸ’» C Compiler

Es necesario tener un compilador de C instalado (como gcc) para compilar el cÃ³digo fuente.

### LibrerÃ­a `cJSON`:

Este proyecto requiere la librerÃ­a `cJSON` para trabajar con archivos JSON en C.  
 Puedes encontrarla y consultar cÃ³mo instalarla en su repositorio oficial:

ğŸ‘‰ [https://github.com/DaveGamble/cJSON](https://github.com/DaveGamble/cJSON)

### ğŸ“¦ Python

AsegÃºrate de tener Python instalado junto con las siguientes bibliotecas:

- json
- os
- sys
- matplotlib
- numpy

## CompilaciÃ³n y EjecuciÃ³n

### 1. **CompilaciÃ³n**

Para compilar el proyecto, usa el siguiente comando:

```bash
make
```

Este comando compilarÃ¡ el cÃ³digo en modo release por defecto (optimizado). Si prefieres compilar en modo debug para facilitar la depuraciÃ³n, puedes usar:

```bash
make debug
```

### 2. Ejecutar el Programa

Una vez compilado el proyecto, puedes ejecutar el ejecutable generado (llamado main) con los siguientes parÃ¡metros:

```bash
./main <poblacion> <generaciones> <archivo> <numero_de_clientes>
```

Ejemplo:

```bash
./main 50 100 C100 25
```

- poblacion: el tamaÃ±o de la poblaciÃ³n para el algoritmo.

- generaciones: el nÃºmero de generaciones que el algoritmo debe ejecutar.

- archivo: el archivo de entrada.

- numero_de_clientes: el nÃºmero de clientes o ciudades a considerar en el TSP.

### 3. Limpieza

Si deseas limpiar los archivos generados (archivos objeto, ejecutables, etc.), puedes usar:

```bash
make clean
```

## ğŸ“ Estructura del Proyecto

```bash
.
â”œâ”€â”€ build/                     # Archivos objetos y dependencias generados por el compilador
â”œâ”€â”€ include/                  # Archivos de cabecera (.h)
â”‚   â”œâ”€â”€ aed.h
â”‚   â”œâ”€â”€ configuracion_json.h
â”‚   â”œâ”€â”€ configuracion_tsp.h
â”‚   â”œâ”€â”€ control_memoria.h
â”‚   â”œâ”€â”€ estructuras.h
â”‚   â”œâ”€â”€ lista_flota.h
â”‚   â”œâ”€â”€ lista_ruta.h
â”‚   â”œâ”€â”€ salida_datos.h
â”‚   â”œâ”€â”€ tsp_sa.h
â”‚   â””â”€â”€ vrp_aco.h
â”œâ”€â”€ Instancias/               # Instancias CSV utilizadas en la ejecuciÃ³n
â”‚   â”œâ”€â”€ Instancias_25/
â”‚   â”œâ”€â”€ Instancias_50/
â”‚   â””â”€â”€ Instancias_100/
â”œâ”€â”€ main                      # Ejecutable generado tras compilar
â”œâ”€â”€ makefile                  # Makefile para compilar el proyecto
â”œâ”€â”€ README.md                 # Archivo de documentaciÃ³n
â”œâ”€â”€ Resultados/               # Salidas generadas por la ejecuciÃ³n
â”‚   â”œâ”€â”€ Resultados_25/
â”‚   â”‚   â”œâ”€â”€ Gifs/
â”‚   â”‚   â”œâ”€â”€ Imagenes/
â”‚   â”‚   â””â”€â”€ Json/
â”‚   â”œâ”€â”€ Resultados_50/
â”‚   â”‚   â”œâ”€â”€ Gifs/
â”‚   â”‚   â”œâ”€â”€ Imagenes/
â”‚   â”‚   â””â”€â”€ Json/
â”‚   â””â”€â”€ Resultados_100/
â”‚       â”œâ”€â”€ Gifs/
â”‚       â”œâ”€â”€ Imagenes/
â”‚       â””â”€â”€ Json/
â”œâ”€â”€ src/                      # CÃ³digo fuente del proyecto en C y Python
â”‚   â”œâ”€â”€ aed.c
â”‚   â”œâ”€â”€ configuracion_json.c
â”‚   â”œâ”€â”€ configuracion_tsp.c
â”‚   â”œâ”€â”€ control_memoria.c
â”‚   â”œâ”€â”€ lista_flota.c
â”‚   â”œâ”€â”€ lista_ruta.c
â”‚   â”œâ”€â”€ main.c
â”‚   â”œâ”€â”€ salida_datos.c
â”‚   â”œâ”€â”€ tsp_sa.c
â”‚   â”œâ”€â”€ vrp_aco.c
â”‚   â””â”€â”€ Simulador_TSP/
â”‚       â””â”€â”€ simulador_tsp.py
â””â”€â”€ VRP_Solomon/              # Instancias del benchmark Solomon
    â”œâ”€â”€ VRP_Solomon_25/
    â”‚   â”œâ”€â”€ C100_(25).txt
    â”‚   â”œâ”€â”€ C200_(25).txt
    â”‚   â”œâ”€â”€ R100_(25).txt
    â”‚   â”œâ”€â”€ RC100_(25).txt
    â”œâ”€â”€ VRP_Solomon_50/
    â”‚   â”œâ”€â”€ C100_(50).txt
    â”‚   â”œâ”€â”€ C200_(50).txt
    â”‚   â”œâ”€â”€ R100_(50).txt
    â”‚   â”œâ”€â”€ RC100_(50).txt
    â””â”€â”€ VRP_Solomon_100/
        â”œâ”€â”€ C100_(100).txt
        â”œâ”€â”€ C200_(100).txt
        â”œâ”€â”€ R100_(100).txt
        â””â”€â”€ RC100_(100).txt
```

## âœ… ConclusiÃ³n

El desarrollo de una metaheurÃ­stica hÃ­brida basada en Ant Colony Optimization (ACO) y Recocido Simulado (SA), calibrada automÃ¡ticamente mediante un Algoritmo Evolutivo Diferencial (DE), demostrÃ³ ser una estrategia efectiva para resolver el Problema del Agente Viajero (TSP).

El uso de ACO permitiÃ³ generar soluciones iniciales de alta calidad inspiradas en el comportamiento de las hormigas, mientras que SA refinÃ³ estas soluciones para escapar de Ã³ptimos locales y explorar regiones mÃ¡s prometedoras del espacio de bÃºsqueda. La incorporaciÃ³n del DE automatizÃ³ por completo el ajuste de parÃ¡metros, adaptando la configuraciÃ³n de los algoritmos en funciÃ³n del tamaÃ±o y complejidad del problema.

Gracias a este enfoque hÃ­brido, se obtuvieron rutas mÃ¡s cortas y eficientes con menor intervenciÃ³n manual, haciendo el sistema escalable y versÃ¡til para distintas instancias del TSP. AdemÃ¡s, el uso de rangos adaptativos por tamaÃ±o del problema garantizÃ³ un equilibrio entre precisiÃ³n y eficiencia computacional.

## ğŸš€ Trabajo futuro

Como lÃ­nea futura de trabajo, se propone la integraciÃ³n de otros enfoques metaheurÃ­sticos hÃ­bridos que puedan mejorar la calidad de las soluciones encontradas y reducir el tiempo de cÃ³mputo. TambiÃ©n serÃ­a interesante evaluar el rendimiento del algoritmo propuesto con diferentes tipos de instancias del problema.

AdemÃ¡s, se podrÃ­a explorar la paralelizaciÃ³n del algoritmo utilizando tÃ©cnicas de programaciÃ³n concurrente o programaciÃ³n paralela, con el fin de acelerar el proceso de optimizaciÃ³n en instancias de mayor tamaÃ±o.

## âœ… Consideraciones finales

Este trabajo busca contribuir al estudio y soluciÃ³n del problema TSP mediante la implementaciÃ³n de algoritmos bioinspirados. Se invita a la comunidad a explorar, reutilizar y mejorar el cÃ³digo segÃºn sus necesidades.

## ğŸ‘¥ Contribuciones

- ğŸ§‘â€ğŸ« **Dr. Edwin Montes Orozco**  
  Director de PT y responsable del acompaÃ±amiento acadÃ©mico durante el desarrollo del proyecto.

- ğŸ‘¨â€ğŸ’» **Alejandro MartÃ­nez GuzmÃ¡n**  
  Autor del proyecto. Encargado del diseÃ±o, implementaciÃ³n y documentaciÃ³n del sistema de optimizaciÃ³n.

- ğŸ§ª **Jaime LÃ³pez Lara**  
  Ayudante en la ejecuciÃ³n del cÃ³digo y recolecciÃ³n de resultados.

## ğŸ“ Licencia

Este proyecto estÃ¡ licenciado bajo los tÃ©rminos de la licencia MIT.  
Consulta el archivo [LICENSE](./LICENSE) para mÃ¡s detalles.
